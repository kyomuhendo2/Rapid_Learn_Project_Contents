{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "MZ5m7fAPyBTF"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import glob\n",
        "import re\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For Google Drive mounting in Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMhmVzJRzwmV",
        "outputId": "c67ab052-66f9-4645-a701-bf996b727b09"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TASK 1: Reading Files from Google Drive & Data Preprocessing\n",
        "# ------------------------------\n",
        "# Defining the folder containing your .txt files on Google Drive\n",
        "data_text = '/content/text_data'"
      ],
      "metadata": {
        "id": "w6Tlh4y_z6Um"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract label from filename.\n",
        "# For example, files starting with \"positive\" or \"negative\" are assigned accordingly.\n",
        "def extract_label(filename):\n",
        " base = os.path.basename(filename)\n",
        " if base.startswith('positive'):\n",
        "  return 'positive'\n",
        " elif base.startswith('negative'):\n",
        "  return 'negative'\n",
        " else:\n",
        "  return 'unknown'\n",
        "\n",
        "# Function to clean and normalize text\n",
        "def clean_text(text):\n",
        " text = text.lower()\n",
        " # Remove non-alphabetic characters (adjust regex to keep language-specific symbols if needed)\n",
        " text = re.sub(r'[^a-z\\s]', '', text)\n",
        " text = re.sub(r'\\s+', ' ', text).strip()\n",
        " return text\n",
        "# Read all .txt files from the folder using glob\n",
        "file_paths = glob.glob(os.path.join(data_text, '*.txt'))\n",
        "print(f\"Found {len(file_paths)} text files.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUHE287_0J12",
        "outputId": "6b73bb6d-d015-4d3a-9c01-1c06dbd53a15"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 12 text files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lists to store the document text and corresponding labels\n",
        "documents = []\n",
        "labels = []\n",
        "\n",
        "for file_path in file_paths:\n",
        " with open(file_path, 'r', encoding='utf-8') as file:\n",
        "  text = file.read()\n",
        " text = clean_text(text)\n",
        " documents.append(text)\n",
        " labels.append(extract_label(file_path))\n",
        "# Create a DataFrame from the documents and labels\n",
        "data = pd.DataFrame({'text': documents, 'label': labels})\n",
        "print(\"Data preview:\")\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pjYyWj51bUm",
        "outputId": "06b34ea4-4da2-4d57-c098-b10afcf05588"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data preview:\n",
            "                                                text     label\n",
            "0  lewic odwoko piny akemo okwerogu okworgi mac a...  negative\n",
            "1  rwo yakobo kadi acel kabedo juda karacel teko ...   unknown\n",
            "2  lewic odwoko piny akemo okwerogu okworgi mac a...  negative\n",
            "3  rwo yakobo kadi acel kabedo juda karacel teko ...   unknown\n",
            "4  teno tyene kica atek meicel adwo meicel teko k...  positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------\n",
        "# TASK 2: Feature Extraction\n",
        "# ------------------------------\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# Initialize a TF-IDF vectorizer that extracts unigrams and bigrams\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
        "features = vectorizer.fit_transform(data['text'])\n",
        "print(f\"Vocabulary size: {len(vectorizer.vocabulary_)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tx-3Tnh31isG",
        "outputId": "c14b33e1-bf22-4993-faab-26d5b7dc3de5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 236\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TASK 3: Model Implementation with Logistic Regression\n",
        "# ------------------------------\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Split the dataset into training and test sets (using stratification to preserve class distribution)\n",
        "X = data['text']\n",
        "y = data['label']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        " X, y, test_size=0.4, random_state=42, stratify=y)\n",
        "\n",
        "# Build a pipeline combining TF-IDF vectorization and logistic regression\n",
        "pipeline = Pipeline([\n",
        " ('tfidf', TfidfVectorizer(ngram_range=(1, 2), lowercase=True)),\n",
        " ('logreg', LogisticRegression(max_iter=1000, solver='liblinear'))\n",
        "])\n",
        "\n",
        "# Optional: Hyperparameter tuning using GridSearchCV for regularization strength\n",
        "param_grid = {\n",
        " 'logreg__C': [0.1, 1, 10],\n",
        " 'logreg__penalty': ['l2']\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(pipeline, param_grid, cv=2, scoring='accuracy', n_jobs=-1)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "#grid = GridSearchCV(pipeline, param_grid, cv=2, scoring='accuracy', n_jobs=-1)\n",
        "#grid.fit(X_train, y_train)\n",
        "print(\"Best hyperparameters found:\", grid.best_params_)\n",
        "\n",
        "# Use the best estimator from grid search\n",
        "best_model = grid.best_estimator_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kEdRNWH10_P",
        "outputId": "8ae070be-d19d-4eba-e0c2-25b9deaa558f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0     negative\n",
            "1      unknown\n",
            "2     negative\n",
            "3      unknown\n",
            "4     positive\n",
            "5     positive\n",
            "6     negative\n",
            "7      unknown\n",
            "8      unknown\n",
            "9     negative\n",
            "10    positive\n",
            "11    positive\n",
            "Name: label, dtype: object\n",
            "Best hyperparameters found: {'logreg__C': 1, 'logreg__penalty': 'l2'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------\n",
        "# TASK 4: Model Evaluation and Analysis\n",
        "# ------------------------------\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "# Predict on the test set\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Accuracy on Test Set:\", accuracy)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(report)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FANrr8rl_43_",
        "outputId": "ae148b46-9e4c-429b-fc54-2882ea65c7c2"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on Test Set: 1.0\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       1.00      1.00      1.00         1\n",
            "    positive       1.00      1.00      1.00         2\n",
            "     unknown       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00         5\n",
            "   macro avg       1.00      1.00      1.00         5\n",
            "weighted avg       1.00      1.00      1.00         5\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1 0 0]\n",
            " [0 2 0]\n",
            " [0 0 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: Examine top features for each class\n",
        "vectorizer = best_model.named_steps['tfidf']\n",
        "classifier = best_model.named_steps['logreg']\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "def print_top_features(class_index, n=10):\n",
        " coef = classifier.coef_[class_index]\n",
        " # Sort features by coefficient weight (largest positive weights)\n",
        " topn = sorted(zip(coef, feature_names), reverse=True)[:n]\n",
        " print(f\"\\nTop features for class '{classifier.classes_[class_index]}':\")\n",
        " for weight, feature in topn:\n",
        "  print(f\"{feature}: {weight:.4f}\")\n",
        "for idx in range(len(classifier.classes_)):\n",
        " print_top_features(idx, n=10)\n",
        "# ------------------------------\n",
        "# (Optional Bonus Task) Predict New Documents\n",
        "# ------------------------------\n",
        "# Example predictions for new sample documents in your local language\n",
        "new_documents = [\n",
        " \"mi obanga kwogo\",\n",
        " \"timo kica ber\",\n",
        " \"Rwot doŋ omio piny ocido oko icuc i Cion\",\n",
        " \"Oneko jo luŋ a yam miowa owakere i yomcuny\",\n",
        " \"myero ijale odoco iyom cuny me dwoko kwo ni bote\",\n",
        " \"Rwot onwoŋo doŋ omoko tammere oko\"\n",
        "]\n",
        "new_predictions = best_model.predict(new_documents)\n",
        "print(\"\\nPredictions for new documents:\")\n",
        "for doc, pred in zip(new_documents, new_predictions):\n",
        " print(f\"Text: {doc}\\nPredicted Label: {pred}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmBcLT52zrGF",
        "outputId": "a7ce47fe-e24d-4c34-a5a5-43978083565e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top features for class 'negative':\n",
            "akemo: 0.3184\n",
            "goba: 0.2504\n",
            "okwero: 0.1878\n",
            "mac: 0.1846\n",
            "rwenyowu arwenya: 0.1252\n",
            "rwenyowu: 0.1252\n",
            "owille: 0.1252\n",
            "okwero goba: 0.1252\n",
            "goba rwenyowu: 0.1252\n",
            "arwenya okwero: 0.1252\n",
            "\n",
            "Top features for class 'positive':\n",
            "adwo: 0.3075\n",
            "tyene: 0.2153\n",
            "teno tyene: 0.2153\n",
            "teno: 0.2153\n",
            "yomcuny teno: 0.1845\n",
            "yomcuny: 0.1845\n",
            "tyene adwo: 0.1845\n",
            "teko konyogi: 0.1845\n",
            "owakere yomcuny: 0.1845\n",
            "owakere: 0.1845\n",
            "\n",
            "Top features for class 'unknown':\n",
            "icrael: 0.2515\n",
            "yakobo: 0.1692\n",
            "teko icrael: 0.1692\n",
            "karacel teko: 0.1692\n",
            "karacel: 0.1692\n",
            "kabedo juda: 0.1692\n",
            "kabedo: 0.1692\n",
            "juda karacel: 0.1692\n",
            "juda: 0.1692\n",
            "acel kabedo: 0.1692\n",
            "\n",
            "Predictions for new documents:\n",
            "Text: mi obanga kwogo\n",
            "Predicted Label: negative\n",
            "\n",
            "Text: timo kica ber\n",
            "Predicted Label: negative\n",
            "\n",
            "Text: Rwot doŋ omio piny ocido oko icuc i Cion\n",
            "Predicted Label: negative\n",
            "\n",
            "Text: Oneko jo luŋ a yam miowa owakere i yomcuny\n",
            "Predicted Label: positive\n",
            "\n",
            "Text: myero ijale odoco iyom cuny me dwoko kwo ni bote\n",
            "Predicted Label: negative\n",
            "\n",
            "Text: Rwot onwoŋo doŋ omoko tammere oko\n",
            "Predicted Label: negative\n",
            "\n"
          ]
        }
      ]
    }
  ]
}